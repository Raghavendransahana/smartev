{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc953fff",
   "metadata": {},
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4fdc1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gradio as gr\n",
    "import openai\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "from dotenv import load_dotenv\n",
    "import speech_recognition as sr\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94d2fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a38d3dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI()\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f2479d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"\"\"\n",
    "You are an advanced EV Battery & Vehicle Assistant specialized in answering queries about electric vehicles (EVs) in India, including brands like Tata, Mahindra, MG, Hyundai, Kia, BYD, and others.\n",
    "Your purpose is to provide accurate, clear, and useful information based only on official EV manuals, technical documentation, verified specifications, and authentic sources.\n",
    "\n",
    "Guidelines:\n",
    "\n",
    "Cover all aspects of EVs in India: battery (SoH, RUL, charging cycles, warnings, troubleshooting), vehicle performance, charging infrastructure, warranty, and usage best practices.\n",
    "\n",
    "When answering, always use simple, human-like language and avoid unnecessary jargon.\n",
    "\n",
    "If a query is vague, interpret it intelligently and provide the most relevant and helpful explanation instead of rejecting it.\n",
    "\n",
    "Stay factual and grounded in available manuals, datasets, or trusted references‚Äînever invent details.\n",
    "\n",
    "Structure answers in a way that is easy to follow, with step-by-step explanations when needed.\n",
    "\n",
    "Response Format:\n",
    "Answer: [Clear and concise explanation]\n",
    "Reference: [Mention the manual/section/source if available]\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "644019a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(user_text):\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_MESSAGE},\n",
    "            {\"role\": \"user\", \"content\": user_text}\n",
    "        ]\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    # Convert text to speech\n",
    "    tts = gTTS(text=answer, lang=\"en\")\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as fp:\n",
    "        tts.save(fp.name)\n",
    "        audio_path = fp.name\n",
    "\n",
    "    return answer, audio_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631f668",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_audio(audio_file):\n",
    "    print(f\"Audio file received: {audio_file}\")  # Debug print\n",
    "    \n",
    "    if audio_file is None:\n",
    "        return \"‚ö†Ô∏è No audio file received. Please record audio first!\", None\n",
    "    \n",
    "    try:\n",
    "        print(f\"Processing audio file: {audio_file}\")\n",
    "        \n",
    "        # Check if file exists and has content\n",
    "        if not os.path.exists(audio_file):\n",
    "            return \"‚ùå Audio file not found!\", None\n",
    "            \n",
    "        file_size = os.path.getsize(audio_file)\n",
    "        print(f\"Audio file size: {file_size} bytes\")\n",
    "        \n",
    "        if file_size == 0:\n",
    "            return \"‚ùå Audio file is empty. Please record again!\", None\n",
    "        \n",
    "        # Step 1: Transcribe audio to text using Whisper\n",
    "        with open(audio_file, \"rb\") as f:\n",
    "            transcript = client.audio.transcriptions.create(\n",
    "                model=\"whisper-1\",\n",
    "                file=f,\n",
    "                response_format=\"text\"\n",
    "            )\n",
    "        \n",
    "        user_text = transcript.strip() if isinstance(transcript, str) else transcript.text.strip()\n",
    "        print(f\"Transcribed text: {user_text}\")\n",
    "        \n",
    "        if not user_text:\n",
    "            return \"‚ùå Could not understand the audio. Please speak clearly and try again!\", None\n",
    "        \n",
    "        # Step 2: Get answer from chatbot\n",
    "        return get_answer(user_text)\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"‚ùå Audio processing error: {str(e)}\"\n",
    "        print(error_msg)\n",
    "        return error_msg, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1465851d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_text(user_input):\n",
    "    return get_answer(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74503406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\gradio\\queueing.py\", line 745, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\gradio\\blocks.py\", line 1623, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\gradio\\utils.py\", line 915, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\sajit\\AppData\\Local\\Temp\\ipykernel_42108\\2757058679.py\", line 4, in chatbot_audio\n",
      "    transcript = client.audio.transcriptions.create(\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\openai\\_utils\\_utils.py\", line 286, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\openai\\resources\\audio\\transcriptions.py\", line 333, in create\n",
      "    return self._post(  # type: ignore[return-value]\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"d:\\kpr-hackathon\\chat\\lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.RateLimitError: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}\n"
     ]
    }
   ],
   "source": [
    "# Simple Voice Interface - WORKING VERSION\n",
    "with gr.Blocks(title=\"EV Voice Assistant\") as demo:\n",
    "    gr.Markdown(\"## üîã EV Battery Twin Assistant (Voice Enabled)\")\n",
    "    gr.Markdown(\"### üé§ Record your question and click Submit!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            mic_input = gr.Audio(\n",
    "                sources=[\"microphone\"], \n",
    "                type=\"filepath\", \n",
    "                label=\"üé§ Record Your Question\",\n",
    "                show_download_button=False\n",
    "            )\n",
    "            \n",
    "            speech_btn = gr.Button(\"üé§ Process Voice\", variant=\"primary\", size=\"lg\")\n",
    "            \n",
    "        with gr.Column(scale=1):\n",
    "            text_input = gr.Textbox(\n",
    "                label=\"üí¨ Or Type Your Question\", \n",
    "                placeholder=\"Ask about Tata EVs...\",\n",
    "                lines=3\n",
    "            )\n",
    "            \n",
    "            text_btn = gr.Button(\"üìù Send Text\", variant=\"secondary\", size=\"lg\")\n",
    "\n",
    "    with gr.Row():\n",
    "        text_output = gr.Textbox(label=\"ü§ñ Assistant Answer\", lines=5)\n",
    "        \n",
    "    with gr.Row():\n",
    "        audio_output = gr.Audio(label=\"üîä Listen to Response\", autoplay=True)\n",
    "\n",
    "    # Handle speech input\n",
    "    speech_btn.click(\n",
    "        fn=chatbot_audio, \n",
    "        inputs=mic_input, \n",
    "        outputs=[text_output, audio_output],\n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "    # Handle text input  \n",
    "    text_btn.click(\n",
    "        fn=chatbot_text, \n",
    "        inputs=text_input, \n",
    "        outputs=[text_output, audio_output],\n",
    "        show_progress=True\n",
    "    )\n",
    "    \n",
    "    # Also allow Enter key for text\n",
    "    text_input.submit(\n",
    "        fn=chatbot_text, \n",
    "        inputs=text_input, \n",
    "        outputs=[text_output, audio_output]\n",
    "    )\n",
    "\n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"**üéØ How to use:** Record audio ‚Üí Click 'üé§ Process Voice' ‚Üí Get answer!\")\n",
    "\n",
    "demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5fbb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QUICK AUDIO TEST - Run this first!\n",
    "def test_audio_recording(audio_file):\n",
    "    if audio_file is None:\n",
    "        return \"‚ùå No audio recorded\"\n",
    "    \n",
    "    if os.path.exists(audio_file):\n",
    "        size = os.path.getsize(audio_file)\n",
    "        return f\"‚úÖ Audio recorded successfully! File size: {size} bytes\"\n",
    "    else:\n",
    "        return \"‚ùå Audio file not found\"\n",
    "\n",
    "with gr.Blocks() as audio_test:\n",
    "    gr.Markdown(\"## üß™ Audio Recording Test\")\n",
    "    gr.Markdown(\"Test if your microphone is working:\")\n",
    "    \n",
    "    test_audio = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Record Test Audio\")\n",
    "    test_btn = gr.Button(\"Test Recording\")\n",
    "    test_result = gr.Textbox(label=\"Test Result\")\n",
    "    \n",
    "    test_btn.click(test_audio_recording, inputs=test_audio, outputs=test_result)\n",
    "\n",
    "# Uncomment to run the test:\n",
    "# audio_test.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c793001",
   "metadata": {},
   "source": [
    "# Just ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "06c92092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_text(user_input, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}]\n",
    "    for user, bot in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": bot})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=MODEL,\n",
    "        messages=messages\n",
    "    )\n",
    "    answer = response.choices[0].message.content\n",
    "\n",
    "    history.append((user_input, answer))\n",
    "    return history, history, \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "104298d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajit\\AppData\\Local\\Temp\\ipykernel_42108\\3500426637.py:4: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Chat with Flexi\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Flexi EV Assistant\")\n",
    "\n",
    "    chatbot = gr.Chatbot(label=\"Chat with Flexi\")\n",
    "    text_input = gr.Textbox(label=\"Ask your question\", placeholder=\"Type here...\")\n",
    "\n",
    "    state = gr.State([])\n",
    "\n",
    "    text_input.submit(\n",
    "        chatbot_text,\n",
    "        \n",
    "        inputs=[text_input, state],\n",
    "        outputs=[chatbot, state, text_input]  # <--- include text_input here\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806e28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b378b71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sajit\\AppData\\Local\\Temp\\ipykernel_10348\\2396453029.py:57: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* Running on public URL: https://bfbd8fb3f3b5f22da9.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
      "* Running on public URL: https://bfbd8fb3f3b5f22da9.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bfbd8fb3f3b5f22da9.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Complete Speech-Enabled Chatbot with History\n",
    "def chatbot_with_speech(user_input, audio_input, history):\n",
    "    # Handle audio input if provided\n",
    "    if audio_input is not None:\n",
    "        try:\n",
    "            with open(audio_input, \"rb\") as f:\n",
    "                transcript = client.audio.transcriptions.create(\n",
    "                    model=\"whisper-1\",\n",
    "                    file=f\n",
    "                )\n",
    "            user_input = transcript.text\n",
    "        except Exception as e:\n",
    "            return history + [(\"Audio Error\", f\"Could not process audio: {str(e)}\")], history, \"\", None\n",
    "    \n",
    "    if not user_input or not user_input.strip():\n",
    "        return history, history, \"\", None\n",
    "    \n",
    "    # Build conversation context\n",
    "    messages = [{\"role\": \"system\", \"content\": SYSTEM_MESSAGE}]\n",
    "    for user, bot in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": bot})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    \n",
    "    try:\n",
    "        # Get AI response\n",
    "        response = client.chat.completions.create(\n",
    "            model=MODEL,\n",
    "            messages=messages\n",
    "        )\n",
    "        answer = response.choices[0].message.content\n",
    "        \n",
    "        # Convert answer to speech\n",
    "        tts = gTTS(text=answer, lang=\"en\")\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as fp:\n",
    "            tts.save(fp.name)\n",
    "            audio_path = fp.name\n",
    "        \n",
    "        # Update history\n",
    "        new_history = history + [(user_input, answer)]\n",
    "        return new_history, new_history, \"\", audio_path\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_msg = f\"Error: {str(e)}\"\n",
    "        new_history = history + [(user_input, error_msg)]\n",
    "        return new_history, new_history, \"\", None\n",
    "\n",
    "# Launch the complete interface\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as speech_demo:\n",
    "    gr.Markdown(\"# SmartEV Assistant - Voice & Text Enabled\")\n",
    "    gr.Markdown(\"Ask questions about EVs using **voice** or **text**!\")\n",
    "    gr.Markdown(\" **Allow microphone access** when prompted by your browser!\")\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=3):\n",
    "            chatbot = gr.Chatbot(\n",
    "                label=\"EV Assistant Chat\", \n",
    "                height=400,\n",
    "                show_copy_button=True\n",
    "            )\n",
    "        \n",
    "        with gr.Column(scale=1):\n",
    "            audio_output = gr.Audio(\n",
    "                label=\" Listen to Response\",\n",
    "                autoplay=False,\n",
    "                show_download_button=True\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=2):\n",
    "            text_input = gr.Textbox(\n",
    "                label=\" Type your question\",\n",
    "                placeholder=\"Ask about EV batteries, charging, maintenance...\",\n",
    "                lines=2\n",
    "            )\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            audio_input = gr.Audio(\n",
    "                sources=[\"microphone\"],\n",
    "                type=\"filepath\",\n",
    "                label=\"üé§ Record Question\",\n",
    "                format=\"wav\",\n",
    "                show_download_button=False\n",
    "            )\n",
    "    \n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Send Message\", variant=\"primary\", size=\"lg\")\n",
    "        voice_btn = gr.Button(\"üé§ Send Voice\", variant=\"secondary\", size=\"lg\")\n",
    "        clear_btn = gr.Button(\"Clear Chat\", variant=\"stop\")\n",
    "    \n",
    "    # State to maintain conversation history\n",
    "    chat_state = gr.State([])\n",
    "    \n",
    "    # Handle text input\n",
    "    submit_btn.click(\n",
    "        chatbot_with_speech,\n",
    "        inputs=[text_input, gr.State(None), chat_state],\n",
    "        outputs=[chatbot, chat_state, text_input, audio_output]\n",
    "    )\n",
    "    \n",
    "    # Handle voice input\n",
    "    voice_btn.click(\n",
    "        chatbot_with_speech,\n",
    "        inputs=[gr.State(\"\"), audio_input, chat_state],\n",
    "        outputs=[chatbot, chat_state, text_input, audio_output]\n",
    "    )\n",
    "    \n",
    "    # Also allow Enter key for text input\n",
    "    text_input.submit(\n",
    "        chatbot_with_speech,\n",
    "        inputs=[text_input, gr.State(None), chat_state],\n",
    "        outputs=[chatbot, chat_state, text_input, audio_output]\n",
    "    )\n",
    "    \n",
    "    # Clear chat history\n",
    "    clear_btn.click(\n",
    "        lambda: ([], []),\n",
    "        outputs=[chatbot, chat_state]\n",
    "    )\n",
    "    \n",
    "    gr.Markdown(\"---\")\n",
    "    gr.Markdown(\"** Usage Tips:**\")\n",
    "    gr.Markdown(\"- **Text:** Type and press Enter or click 'Send Message'\")\n",
    "    gr.Markdown(\"- **Voice:** Record audio, then click 'üé§ Send Voice'\")\n",
    "    gr.Markdown(\"- **Browser:** Make sure to allow microphone permissions!\")\n",
    "\n",
    "speech_demo.launch(share=True, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f83ef806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick Microphone Test\n",
    "def test_microphone():\n",
    "    import gradio as gr\n",
    "    \n",
    "    def process_test_audio(audio):\n",
    "        if audio is None:\n",
    "            return \"‚ùå No audio received. Check microphone permissions!\"\n",
    "        else:\n",
    "            return f\"‚úÖ Audio received! File: {audio}\"\n",
    "    \n",
    "    with gr.Blocks() as mic_test:\n",
    "        gr.Markdown(\"## üé§ Microphone Test\")\n",
    "        gr.Markdown(\"Record a short audio to test if microphone works:\")\n",
    "        \n",
    "        test_audio = gr.Audio(\n",
    "            sources=[\"microphone\"], \n",
    "            type=\"filepath\", \n",
    "            label=\"Test Recording\",\n",
    "            format=\"wav\"\n",
    "        )\n",
    "        test_btn = gr.Button(\"Test Audio\")\n",
    "        result = gr.Textbox(label=\"Test Result\")\n",
    "        \n",
    "        test_btn.click(process_test_audio, inputs=test_audio, outputs=result)\n",
    "    \n",
    "    return mic_test\n",
    "\n",
    "# Uncomment to run microphone test\n",
    "# mic_test_demo = test_microphone()\n",
    "# mic_test_demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f6c68d2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'audio_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43maudio_test\u001b[49m\u001b[38;5;241m.\u001b[39mlaunch()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'audio_test' is not defined"
     ]
    }
   ],
   "source": [
    "audio_test.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b5b430",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
